# 计数
## 场景描述
- 多个线程在同时更新计数器
- 多个线程在获取计数器

## 简单加
```
1 unsigned long counter = 0;
2
3 static __inline__ void inc_count(void)
4 {
5 WRITE_ONCE(counter, READ_ONCE(counter) + 1);
6 }
7
8 static __inline__ unsigned long read_count(void)
9 {
10 return READ_ONCE(counter);
11 }
```
很明显count++并发会有问题

## 原子操作
```
1 atomic_t counter = ATOMIC_INIT(0);
2
3 static __inline__ void inc_count(void)
4 {
5 atomic_inc(&counter);
6 }
7
8 static __inline__ long read_count(void)
9 {
10 return atomic_read(&counter);
11 }
```
原子操作虽然保证了计数的准确性，但在性能上损失很大
![enter image description here](https://lh3.googleusercontent.com/z8ng0eRBCzxNLXnzstprhA7kAKeIZTKhzgCfkNMVtkCF4SS5X7VFEMu3QWDWdphmKoh2QCakN9I9)
单一线程执行算是CAS乐观情况
多个线程并发算是CAS竞争糟糕情况

## 场景细分
通用的解决方案不能很好的解决所有的问题，现针对不同场景细分解决方案
### 多写少读（网络报文计数）
思路：减少频繁操作的竞争度，代价是增加频率低操作的竞争度

#### 最终一致性实现
```
1 DEFINE_PER_THREAD(unsigned long, counter);
2 unsigned long global_count;
3 int stopflag;
4
5 static __inline__ void inc_count(void)
6 {
7 	unsigned long *p_counter = &__get_thread_var(counter);
8   //应该就是单纯的寄存器++，性能很高
9  	WRITE_ONCE(*p_counter, *p_counter + 1);
10 }
11
12 static __inline__ unsigned long read_count(void)
13 {
14 	return READ_ONCE(global_count);
15 }
16
17 void *eventual(void *arg)
18 {
19 int t;
20 unsigned long sum;
21
22 while (READ_ONCE(stopflag) < 3) {
23 	sum = 0;
24 	for_each_thread(t)
        //获取OLD内容也无所谓
25 		sum += READ_ONCE(per_thread(counter, t));
26 		WRITE_ONCE(global_count, sum);
27 		poll(NULL, 0, 1);
28 		if (READ_ONCE(stopflag)) {
29 			smp_mb();
30 			WRITE_ONCE(stopflag, stopflag + 1);
31 		}
32 	}
33 	return NULL;
34 }
35
36 void count_init(void)
37 {
38 int en;
39 thread_id_t tid;
40
41 en = pthread_create(&tid, NULL, eventual, NULL);
42 if (en != 0) {
43 	fprintf(stderr, "pthread_create: %s\n", strerror(en));
44 	exit(EXIT_FAILURE);
45 }
46 }
47
48 void count_cleanup(void)
49 {
50 WRITE_ONCE(stopflag, 1);
51 while (READ_ONCE(stopflag) < 3)
52 poll(NULL, 0, 1);
53 smp_mb();
54 }
```
读和写代价都很小，缺点是需要维护定时任务更新。

#### 近似上限（多个计数器累积到特定值暂停）
类似资源分配，可以cai
<!--stackedit_data:
eyJoaXN0b3J5IjpbMzY3ODIzNjYsLTE0MTgzMjk2NTQsLTQzOD
Q0MjU2MSw3MzA5OTgxMTZdfQ==
-->